{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binram077/genetic-algorithm-from-scratch/blob/main/4inarowevoltution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this project is not so good at playing but I built the algorithm from scratch so you'll need to pardon me"
      ],
      "metadata": {
        "id": "8qWcqTfGsoGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0UQnpUYZU04"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# building the 4 in a row simulation"
      ],
      "metadata": {
        "id": "1gJB2F_qpEGG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v34JR0-qnAE-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "DictionaryPoint = {\"negative\":0.0,\"positive\":1.0,\"teko\":0.5}\n",
        "players = [\"negative\",\"positive\",]\n",
        "\n",
        "class board():\n",
        "  def __init__(self):\n",
        "    self.Boardarray = np.full((6,7),0.0)\n",
        "    self.turn = random.choice([1.0,-1.0])\n",
        "\n",
        "  def new_board(_board = None,_turn = None):\n",
        "    n_board = board()\n",
        "    n_board.Boardarray = _board\n",
        "    n_board.turn = _turn\n",
        "    return n_board\n",
        "\n",
        "\n",
        "  def nextStates(self):\n",
        "    States = []\n",
        "    #one state for each column -> len(self.Boardarray.T)\n",
        "    for i in range(len(self.Boardarray.T)):\n",
        "      #check the column is not full\n",
        "      if self.Boardarray[0][i] is not 0:\n",
        "        s = self.Boardarray.copy()\n",
        "        top = -1\n",
        "        #run on the column to find the last row avialable\n",
        "        for j in range(len(s)):\n",
        "          if s[j][i] == 0:\n",
        "            top = j\n",
        "        #put the token in the row\n",
        "        if top != -1:\n",
        "          s[top][i] = self.turn\n",
        "          States.append((board.new_board(s,self.turn * -1),i))\n",
        "    return States\n",
        "\n",
        "  #validated\n",
        "  def sub_check(self,x):\n",
        "    box_type = 0\n",
        "    sum = 0\n",
        "    for i in x:\n",
        "      if box_type == i:\n",
        "        if box_type != 0:\n",
        "          sum += 1\n",
        "      else:\n",
        "        box_type = i\n",
        "        sum = 0\n",
        "      if sum == 3:\n",
        "        return box_type\n",
        "    return 0.0\n",
        "\n",
        "  def play(self,i):\n",
        "    flag = True\n",
        "    for x in self.nextStates():\n",
        "      if i == x[1]:\n",
        "        self.Boardarray = np.copy(x[0].Boardarray)\n",
        "        self.turn *= -1\n",
        "        flag = False\n",
        "    if flag:\n",
        "      print(\"Error this column is full\")\n",
        "\n",
        "  def p_rand(self):\n",
        "    i = random.choice(range(6))\n",
        "    self.play(i)\n",
        "\n",
        "  def CheckWin(self):\n",
        "    #column and rows\n",
        "    sub_check_rows_and_columns = [self.sub_check(x) for x in self.Boardarray] + [self.sub_check(x) for x in self.Boardarray.T]\n",
        "    sub_check_diagonals = [self.sub_check(x) for x in [np.diag(self.Boardarray,i) for i in range(-5,7)]]+[self.sub_check(x) for x in [np.diag(np.fliplr(self.Boardarray),i) for i in range(-5,7)]]\n",
        "    sum_subchecks = sub_check_rows_and_columns + sub_check_diagonals\n",
        "    for x in sum_subchecks:\n",
        "      if x != 0:\n",
        "        return x\n",
        "    return 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the board"
      ],
      "metadata": {
        "id": "FXpE5QKapb04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbmHdfTLpxDU"
      },
      "outputs": [],
      "source": [
        "b = board()\n",
        "while b.CheckWin() == 0:\n",
        "  print(b.Boardarray)\n",
        "  print(b.turn)\n",
        "  b.p_rand()\n",
        "print(b.Boardarray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh38wIAHjgeV"
      },
      "outputs": [],
      "source": [
        "b = board()\n",
        "print(b.Boardarray)\n",
        "print(b.turn)\n",
        "n_s = b.nextStates()\n",
        "for x in n_s:\n",
        "  print(x[0].Boardarray)\n",
        "  print(x[0].turn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# building the neurons, the weights and the agent\n",
        "\n",
        "\n",
        "1.   the neuron is just a container of a number which symbolized how much it fires.\n",
        "2.   the weights are the action when a weight is getting activated it cause the output to fire or unfire as a result to the input neuron.\n",
        "3. the agent contains a neural network and he knows how to evaluate a state and playing accordingly. he also know how to mutate."
      ],
      "metadata": {
        "id": "w-tKJi4bpg-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZofWJGSbxdH"
      },
      "outputs": [],
      "source": [
        "from math import tanh\n",
        "\n",
        "class container():\n",
        "  def __init__(self,_number):\n",
        "    self.x = 0\n",
        "    self.number = _number\n",
        "\n",
        "  def clear(self):\n",
        "    self.x = 0\n",
        "\n",
        "class entrance(container):\n",
        "  def __init__(self,_number):\n",
        "    container.__init__(self,_number)\n",
        "  \n",
        "  def update(self,_x):\n",
        "    self.x = _x\n",
        "  \n",
        "  def output(self):\n",
        "    return self.x\n",
        "\n",
        "class neuron(container):\n",
        "  def __init__(self,_number, _bias = 0):\n",
        "    container.__init__(self,_number)\n",
        "    self.bias = _bias\n",
        "\n",
        "  def get(self,_x):\n",
        "    self.x += _x\n",
        "  \n",
        "  def output(self):\n",
        "    return tanh(self.x / 3) * 3 + self.bias\n",
        "\n",
        "  def ToStr(self):\n",
        "    return \"neuron number \" + str(self.number) + \" has a bias of \" + str(self.bias)\n",
        "\n",
        "class weight():\n",
        "  def __init__(self,_scalar,_input,_output):\n",
        "    self.scalar = _scalar\n",
        "    self.input = _input\n",
        "    self.output = _output\n",
        "\n",
        "  def activate(self,Print = False):\n",
        "    self.output.get(self.input.output() * self.scalar)\n",
        "\n",
        "  def ToStr(self):\n",
        "    return \"from \"+str(self.input.number) + \" to \" + str(self.output.number) + \" with scalar equal to \"+str(self.scalar)\n",
        "\n",
        "\n",
        "\n",
        "class agent():\n",
        "  def __init__(self):\n",
        "    self.entrances = []\n",
        "    for i in range(44):\n",
        "      self.entrances.append(entrance(i))\n",
        "    self.middle_layer = []\n",
        "    self.output = neuron(44)\n",
        "    self.weights = []\n",
        "    self.num_of_neurons = 45\n",
        "  \n",
        "  #validated, but also need to get his color from system\n",
        "  def get_board(self,_board):\n",
        "    for i in range(42):\n",
        "      self.entrances[i].update(_board.Boardarray[i % 6][int(i/6)])\n",
        "    self.entrances[42].update(_board.turn)\n",
        "  \n",
        "  def eval(self,_board):\n",
        "    self.get_board(_board)\n",
        "    for w in self.weights:\n",
        "      w.activate()\n",
        "    val = self.output.output()\n",
        "    self.clear()\n",
        "    return val\n",
        "  \n",
        "  def add_w(self,sc = None,_input = None, _output = None):\n",
        "    if len(self.weights) >= 3000:\n",
        "      return\n",
        "    if sc == None:\n",
        "      sc = random.uniform(-3.0,3.0)\n",
        "    if _input == None:\n",
        "      _input = random.choice(self.middle_layer+self.entrances)\n",
        "    if _output == None:\n",
        "      _output = random.choice(self.middle_layer+[self.output])\n",
        "    w = weight(sc,_input,_output)\n",
        "    self.weights.append(w)\n",
        "  \n",
        "  def add_n(self):\n",
        "    if self.num_of_neurons >= 200:\n",
        "      print(\"error too much neurons\")\n",
        "      return\n",
        "    n = neuron(self.num_of_neurons, random.random())\n",
        "    self.num_of_neurons += 1\n",
        "    for i in range(3):\n",
        "      self.add_w(None,None,n)\n",
        "    self.add_w(None,n,None)\n",
        "    self.middle_layer.append(n)\n",
        "  \n",
        "  def del_w(self):\n",
        "    if len(self.weights) > 0:\n",
        "      self.weights.remove(random.choice(self.weights))\n",
        "\n",
        "  def change_sc(self):\n",
        "    if len(self.weights) > 0:\n",
        "      w = random.choice(self.weights)\n",
        "      w.scalar = random.uniform(-3.0,3.0)\n",
        "\n",
        "  def change_bias(self):\n",
        "    if len(self.middle_layer) > 0:\n",
        "      n = random.choice(self.middle_layer)\n",
        "      n.bias = random.random()\n",
        "\n",
        "  def clear(self):\n",
        "    for x in self.entrances + self.middle_layer + [self.output]:\n",
        "      x.clear()\n",
        "  \n",
        "  def copy(self):\n",
        "    son = agent()\n",
        "    for n in self.middle_layer:\n",
        "      _n = neuron(son.num_of_neurons, random.random())\n",
        "      _n.bias = n.bias\n",
        "      son.num_of_neurons += 1\n",
        "      son.middle_layer.append(_n)\n",
        "    for w in self.weights:\n",
        "      in_node = son.get_neuron_number_x(w.input.number)\n",
        "      out_node = son.get_neuron_number_x(w.output.number)\n",
        "      _scalar = w.scalar\n",
        "      son.add_w(_scalar,in_node,out_node)\n",
        "    return son\n",
        "\n",
        "\n",
        "  def get_neuron_number_x(self,x):\n",
        "    if x < 0:\n",
        "      print(\"Error you can't ask for neuron with a negative number\")\n",
        "      return None\n",
        "    if x < 44:\n",
        "      return self.entrances[x]\n",
        "    if x == 44:\n",
        "      return self.output\n",
        "    return self.middle_layer[x-45]\n",
        "  \n",
        "  def mutate(self):\n",
        "    options = [agent.add_n,agent.add_w,agent.change_bias,agent.change_sc,agent.del_w]\n",
        "    #the number of mutation is determined randomally with the biggest chance to one mutation at a time\n",
        "    funcs = random.choices(options,[4*(200-self.num_of_neurons),3000-len(self.weights),40,70,40],k= random.randint(0,1)+random.randint(0,1) + int((random.randint(0,1)+random.randint(0,1))/2))\n",
        "    for f in funcs:\n",
        "     f(self)\n",
        "\n",
        "  def mutation(self):\n",
        "    son = self.copy()\n",
        "    son.mutate()\n",
        "    return son\n",
        "\n",
        "  def show(self):\n",
        "    print(\"weights:\")\n",
        "    for w in self.weights:\n",
        "      print(w.ToStr())\n",
        "    print(\"neurons:\")\n",
        "    for n in self.middle_layer+[self.output]:\n",
        "      print(n.ToStr())\n",
        "\n",
        "  def choose_move(next_boards_with_indexes):\n",
        "    max_idx = 0\n",
        "    max_prediction = None\n",
        "\n",
        "  def set_color(self,x):\n",
        "    self.entrances[-1].update(x) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the system object simulate the evolution over the generation by letting it agent to fight each other and terminating the losers"
      ],
      "metadata": {
        "id": "yLpZkEYjrGa6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtdWhwIjL0Xc"
      },
      "outputs": [],
      "source": [
        "class system():\n",
        "  def __init__(self):\n",
        "    self.agents = []\n",
        "    for i in range(200):\n",
        "      self.agents.append(agent())\n",
        "      for j in range(3):\n",
        "        self.agents[-1].add_n()\n",
        "    self.champions = []\n",
        "  \n",
        "  def two_agent_fight(self,a,b,ToPrint = False):\n",
        "    fight_board = board()\n",
        "    competitors = [a,b]\n",
        "    random.shuffle(competitors)\n",
        "    competitors_and_colors = [[competitors[0],fight_board.turn],[competitors[1],fight_board.turn * -1]]\n",
        "    current_player_idx = 0\n",
        "    while fight_board.CheckWin() == 0:\n",
        "      if len(fight_board.nextStates()) == 0:\n",
        "        self.champions.append(random.choice(competitors))\n",
        "        return\n",
        "      chosen_state_number = None\n",
        "      chosen_state_evaluation = -5\n",
        "      for n_s in fight_board.nextStates():\n",
        "        competitors_and_colors[current_player_idx][0].set_color(competitors_and_colors[current_player_idx][1])\n",
        "        evaluation = competitors_and_colors[current_player_idx][0].eval(n_s[0])\n",
        "        if evaluation > chosen_state_evaluation:\n",
        "          chosen_state_evaluation = evaluation\n",
        "          chosen_state_number = n_s[1]\n",
        "      fight_board.play(chosen_state_number)\n",
        "      if ToPrint:\n",
        "        print(fight_board.Boardarray)\n",
        "        print(\"\")\n",
        "      current_player_idx = 1 - current_player_idx\n",
        "    if fight_board.CheckWin() == 0.5:\n",
        "      self.champions.append(random.choice([a,b]))\n",
        "      return\n",
        "    self.champions = self.champions + [x[0] for x in competitors_and_colors if x[1] == fight_board.CheckWin()]\n",
        "\n",
        "  def next_gen(self,PrintFirst = False):\n",
        "    random.shuffle(self.agents)\n",
        "    while len(self.agents) >= 2:\n",
        "      a = self.agents.pop()\n",
        "      b = self.agents.pop()\n",
        "      self.two_agent_fight(a,b,PrintFirst)\n",
        "      PrintFirst = False\n",
        "    self.agents = [x.mutation() for x in self.champions] + self.champions\n",
        "    self.champions = []\n",
        "\n",
        "  def next_gens(self,n):\n",
        "    for i in range(n):\n",
        "      self.next_gen()\n",
        "      if i % 5 == 0:\n",
        "        print(\"this is the \" + str(i) + \"th  generation\")\n",
        "        print(\"------------------------------\\n------------------------------\")\n",
        "        self.next_gen(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the board with the agent"
      ],
      "metadata": {
        "id": "THd8rsIor1hO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GklONTQvW9LO"
      },
      "outputs": [],
      "source": [
        "B = board()\n",
        "for i in range(6):\n",
        "  B.p_rand()\n",
        "print(B.Boardarray)\n",
        "A = agent()\n",
        "A.add_n()\n",
        "A.add_n()\n",
        "A.show()\n",
        "Ason = A.mutation()\n",
        "Ason.show()\n",
        "\n",
        "print(\"evaluation:\")\n",
        "print(A.eval(B))\n",
        "print(\"evaluation 2:\")\n",
        "print(Ason.eval(B))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oMdetL1un14"
      },
      "outputs": [],
      "source": [
        "A = agent()\n",
        "A.add_n()\n",
        "A.add_n()\n",
        "A.add_n()\n",
        "B = agent()\n",
        "B.add_n()\n",
        "B.add_n()\n",
        "B.add_n()\n",
        "S = system()\n",
        "S.two_agent_fight(A,B,True)\n",
        "print(S.champions[0] is A)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the game object is the user interface that let the human player play against one of the agents"
      ],
      "metadata": {
        "id": "sI4tN3uFrnaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ninIbY2BDduo"
      },
      "outputs": [],
      "source": [
        "class game():\n",
        "  def __init__(self,A):\n",
        "    self.Game_agent = A\n",
        "    self.Game_board = board()\n",
        "    print(\"you play the 1 color, would you prefer to start? answer y for yes and n for no\")\n",
        "    letter = input()\n",
        "    if letter == 'y':\n",
        "      self.Game_board.turn = 1.0\n",
        "      return\n",
        "    if letter == 'n':\n",
        "      self.Game_board.turn = -1.0\n",
        "      return\n",
        "    else:\n",
        "      print(\"you can't choose this option\")\n",
        "\n",
        "  def start(self):\n",
        "    while self.Game_board.CheckWin() == 0:\n",
        "      print(self.Game_board.Boardarray)\n",
        "      if len(self.Game_board.nextStates()) == 0:\n",
        "        print(\"it's a draw!\")\n",
        "        return\n",
        "      if self.Game_board.turn == 1.0:\n",
        "        print(\"enter your move(a number of a column)\")\n",
        "        self.Game_board.play(int(input())-1)\n",
        "      elif self.Game_board.turn == -1.0:\n",
        "        idx = -1\n",
        "        max_eval = -5\n",
        "        for x in self.Game_board.nextStates():\n",
        "          self.Game_agent.set_color(-1.0)\n",
        "          cur_eval = self.Game_agent.eval(x[0])\n",
        "          if cur_eval > max_eval:\n",
        "            max_eval = cur_eval\n",
        "            idx = x[1]\n",
        "        self.Game_board.play(idx)\n",
        "    print(self.Game_board.Boardarray)\n",
        "    if self.Game_board.CheckWin() == 1.0:\n",
        "      print(\"you won\")\n",
        "    if self.Game_board.CheckWin() == -1.0:\n",
        "      print(\"agent won\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the game and the system and playing against the computer"
      ],
      "metadata": {
        "id": "ipJ5qnvbseic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mcnIqYoI7qK"
      },
      "outputs": [],
      "source": [
        "s = system()\n",
        "s.next_gens(1200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = game(s.agents[0])\n",
        "g.start()"
      ],
      "metadata": {
        "id": "0oa6dZxc7W5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "4inarowevoltution.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfVMldcVk+sLJsY9q7xfr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}